{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Concatenate, Softmax, LayerNormalization, Dropout\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "\n",
    "def neighbours_8(x, y, x_max, y_max):\n",
    "    deltas_x = (-1, 0, 1)\n",
    "    deltas_y = (-1, 0, 1)\n",
    "    for (dx, dy) in itertools.product(deltas_x, deltas_y):\n",
    "        x_new, y_new = x + dx, y + dy\n",
    "        if 0 <= x_new < x_max and 0 <= y_new < y_max and (dx, dy) != (0, 0):\n",
    "            yield x_new, y_new\n",
    "\n",
    "\n",
    "def neighbours_4(x, y, x_max, y_max):\n",
    "    for (dx, dy) in [(1, 0), (0, 1), (0, -1), (-1, 0)]:\n",
    "        x_new, y_new = x + dx, y + dy\n",
    "        if 0 <= x_new < x_max and 0 <= y_new < y_max and (dx, dy) != (0, 0):\n",
    "            yield x_new, y_new\n",
    "\n",
    "\n",
    "def get_neighbourhood_func(neighbourhood_fn):\n",
    "    if neighbourhood_fn == \"4-grid\":\n",
    "        return neighbours_4\n",
    "    elif neighbourhood_fn == \"8-grid\":\n",
    "        return neighbours_8\n",
    "    else:\n",
    "        raise Exception(f\"neighbourhood_fn of {neighbourhood_fn} not possible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "import heapq\n",
    "\n",
    "#DijkstraOutput = namedtuple(\"DijkstraOutput\", [\"shortest_path\", \"is_unique\", \"transitions\"])\n",
    "\n",
    "\n",
    "def dijkstra(matrix, neighbourhood_fn=\"8-grid\", request_transitions=False):\n",
    "\n",
    "    x_max, y_max = matrix.shape\n",
    "    neighbors_func = partial(get_neighbourhood_func(neighbourhood_fn), x_max=x_max, y_max=y_max)\n",
    "\n",
    "    costs = np.full_like(matrix, 1.0e10)\n",
    "    costs[0][0] = matrix[0][0]\n",
    "    num_path = np.zeros_like(matrix)\n",
    "    num_path[0][0] = 1\n",
    "    priority_queue = [(matrix[0][0], (0, 0))]\n",
    "    certain = set()\n",
    "    transitions = dict()\n",
    "\n",
    "    while priority_queue:\n",
    "        cur_cost, (cur_x, cur_y) = heapq.heappop(priority_queue)\n",
    "        if (cur_x, cur_y) in certain:\n",
    "            pass\n",
    "\n",
    "        for x, y in neighbors_func(cur_x, cur_y):\n",
    "            if (x, y) not in certain:\n",
    "                if matrix[x][y] + costs[cur_x][cur_y] < costs[x][y]:\n",
    "                    costs[x][y] = matrix[x][y] + costs[cur_x][cur_y]\n",
    "                    heapq.heappush(priority_queue, (costs[x][y], (x, y)))\n",
    "                    transitions[(x, y)] = (cur_x, cur_y)\n",
    "                    num_path[x, y] = num_path[cur_x, cur_y]\n",
    "                elif matrix[x][y] + costs[cur_x][cur_y] == costs[x][y]:\n",
    "                    num_path[x, y] += 1\n",
    "\n",
    "        certain.add((cur_x, cur_y))\n",
    "    # retrieve the path\n",
    "    cur_x, cur_y = x_max - 1, y_max - 1\n",
    "    on_path = np.zeros_like(matrix)\n",
    "    on_path[-1][-1] = 1\n",
    "    while (cur_x, cur_y) != (0, 0):\n",
    "        cur_x, cur_y = transitions[(cur_x, cur_y)]\n",
    "        on_path[cur_x, cur_y] = 1.0\n",
    "\n",
    "    is_unique = num_path[-1, -1] == 1\n",
    "\n",
    "    return on_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create a grid graph and enumerate all shortest paths\n",
    "G = nx.Graph() # 5x5 grid\n",
    "\n",
    "#G = G.to_directed()\n",
    "k = 12\n",
    "\n",
    "for i in range(0, k):\n",
    "    for j in range(0, k-1):\n",
    "        G.add_edge(j+i*k, j+1+i*k, weight=0)\n",
    "\n",
    "for i in range(0, k-1):\n",
    "    for j in range(0, k):\n",
    "        G.add_edge(j+i*k, j+(i+1)*k, weight=0)\n",
    "    \n",
    "for i in range(0, k-1):\n",
    "    for j in range(0, k-1):\n",
    "        G.add_edge(j+i*k, j+1+(i+1)*k, weight=0)\n",
    "        \n",
    "for i in range(0, k-1):\n",
    "    for j in range(0, k-1):\n",
    "        G.add_edge(j+1+i*k, j+(i+1)*k, weight=0)\n",
    "    \n",
    "#nx.draw(G)\n",
    "#plt.show()\n",
    "#path_gen = nx.all_shortest_paths(G, source=0, target=k*k-1, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "weight_dict=nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "num_samples = 100000\n",
    "sampled_paths = set()\n",
    "\n",
    "for i in range(num_samples):\n",
    "    for j, t in enumerate(weight_dict):\n",
    "        weight_dict[t]=random.random()*5\n",
    "    nx.set_edge_attributes(G, weight_dict,'weight')\n",
    "    path_list = tuple(nx.shortest_path(G, source=0, target=k*k-1, weight='weight'))\n",
    "    sampled_paths.add(path_list)\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "sampled_paths = list(map(list, sampled_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_binary = np.zeros((num_samples, 144))\n",
    "for row_index, row in enumerate(sampled_paths):\n",
    "    for col_index, item in enumerate(row):\n",
    "        samples_binary[row_index, item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_tf = tf.transpose(tf.cast(samples_binary, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-9dea1e557495>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[0mtrain_true_weights\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_prefix\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"_vertex_weights.npy\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m mean, std = (\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m         \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m       )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# let's load the images of the grids\n",
    "train_prefix = \"train\"\n",
    "val_prefix = \"test\"\n",
    "data_suffix = \"maps\"\n",
    "true_weights_suffix = \"\"\n",
    "\n",
    "data_dir = \"/mnt/data-c305/mniepert/reason/12x12\"\n",
    "\n",
    "train_data_path = os.path.join(data_dir, train_prefix + \"_\" + data_suffix + \".npy\")\n",
    "\n",
    "if os.path.exists(train_data_path):\n",
    "    train_inputs = np.load(os.path.join(data_dir, train_prefix + \"_\" + data_suffix + \".npy\")).astype(np.float32)\n",
    "    train_labels = np.load(os.path.join(data_dir, train_prefix + \"_shortest_paths.npy\"))\n",
    "    train_true_weights = np.load(os.path.join(data_dir, train_prefix + \"_vertex_weights.npy\"))\n",
    "mean, std = (\n",
    "        np.mean(train_inputs, axis=(0), keepdims=True),\n",
    "        np.std(train_inputs, axis=(0), keepdims=True),\n",
    "      )\n",
    "print(mean.shape)\n",
    "train_inputs -= mean\n",
    "train_inputs /= std\n",
    "\n",
    "\n",
    "val_inputs = np.load(os.path.join(data_dir, val_prefix + \"_\" + data_suffix + \".npy\")).astype(np.float32)\n",
    "val_labels = np.load(os.path.join(data_dir, val_prefix + \"_shortest_paths.npy\"))\n",
    "val_true_weights = np.load(os.path.join(data_dir, val_prefix + \"_vertex_weights.npy\"))\n",
    "val_inputs -= mean\n",
    "val_inputs /= std\n",
    "\n",
    "train_labels = train_labels\n",
    "val_labels = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 96, 96, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 1.2, 1.2],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 1.2, 1.2, 1.2],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 0.8, 0.8, 0.8, 0.8],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 0.8, 0.8, 0.8, 0.8],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 0.8, 0.8, 0.8, 0.8, 0.8],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 0.8, 0.8, 0.8, 0.8],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 0.8, 0.8, 0.8, 0.8],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 1.2, 1.2, 0.8],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 7.7, 1.2, 1.2, 1.2, 1.2],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 9.2, 9.2, 1.2],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 9.2, 1.2, 1.2],\n",
       "       [7.7, 7.7, 7.7, 7.7, 7.7, 7.7, 1.2, 1.2, 1.2, 1.2, 9.2, 1.2]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_true_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 96, 96, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_inputs[1].astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_inputs, train_labels)).shuffle(10000000).batch(70)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_inputs, val_labels, val_true_weights)).batch(1)\n",
    "#for element in train_ds:\n",
    "#    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def compute_probs_op(x):\n",
    "    \n",
    "    x_reshaped = tf.reshape(x, [-1, 144])\n",
    "    #print(x_reshaped.shape)\n",
    "        \n",
    "    world_weights = tf.tensordot(x_reshaped, samples_tf, axes=1)\n",
    "    #print(world_weights)\n",
    "    #d = self.samples\n",
    "    variable_weights = tf.tensordot(samples_tf, tf.transpose(world_weights), axes=1)\n",
    "    #print(variable_weights)\n",
    "    # here we need to insert the sampling part\n",
    "        \n",
    "    Z = tf.reduce_sum(world_weights, 1)\n",
    "    #print(Z)\n",
    "        \n",
    "    normalized_variable_weights = tf.math.divide(variable_weights, Z)\n",
    "    #print(normalized_variable_weights)\n",
    "             \n",
    "    result = tf.reshape(normalized_variable_weights, [-1, 12, 12])\n",
    "    #print(result)\n",
    "        \n",
    "    def custom_grad(dy):\n",
    "        grad = dy\n",
    "        return grad\n",
    "    \n",
    "    return result, custom_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, filter_num, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        if stride != 1:\n",
    "            self.downsample = tf.keras.Sequential()\n",
    "            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                       kernel_size=(1, 1),\n",
    "                                                       strides=stride))\n",
    "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        residual = self.downsample(inputs)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
    "    res_block = tf.keras.Sequential()\n",
    "    res_block.add(BasicBlock(filter_num, stride=stride))\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        res_block.add(BasicBlock(filter_num, stride=1))\n",
    "\n",
    "    return res_block\n",
    "\n",
    "\n",
    "class ResNet18(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
    "                                            kernel_size=(7, 7),\n",
    "                                            strides=2,\n",
    "                                            padding=\"same\",\n",
    "                                            use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
    "                                               strides=2,\n",
    "                                               padding=\"same\")\n",
    "        self.layer1 = make_basic_block_layer(filter_num=64, blocks=2)\n",
    "\n",
    "        output_shape = (int(12), int(12))\n",
    "        self.adaptivepool = tfa.layers.AdaptiveAveragePooling2D(output_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.layer1(x, training=training)\n",
    "        x = self.adaptivepool(x)\n",
    "        output = tf.math.reduce_mean(x, axis=3)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "class ResNet18Inference(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet18Inference, self).__init__()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
    "                                            kernel_size=(7, 7),\n",
    "                                            strides=2,\n",
    "                                            padding=\"same\",\n",
    "                                            use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
    "                                               strides=2,\n",
    "                                               padding=\"same\")\n",
    "        self.layer1 = make_basic_block_layer(filter_num=64, blocks=2)\n",
    "\n",
    "        output_shape = (int(12), int(12))\n",
    "        self.adaptivepool = tfa.layers.AdaptiveAveragePooling2D(output_shape)\n",
    "\n",
    "        \n",
    "    def set_sample_matrix(self, samples_in):\n",
    "        self.samples = tf.transpose(tf.cast(samples_in, tf.float32))\n",
    "        print(self.samples.shape)\n",
    "        \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.layer1(x, training=training)\n",
    "        x = self.adaptivepool(x)\n",
    "        x_logit = tf.math.reduce_mean(x, axis=3)\n",
    "        x_prob = tf.math.sigmoid(-x_logit)\n",
    "        \n",
    "        inference_x = compute_probs_op(-x_logit)\n",
    "        \n",
    "        return x_prob, x_logit, inference_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100000)\n"
     ]
    }
   ],
   "source": [
    "model_inference = ResNet18Inference()\n",
    "model_inference.set_sample_matrix(samples_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_inference(train_inputs[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 12, 12), dtype=float32, numpy=\n",
       " array([[[0.4353631 , 0.43278903, 0.4366324 , 0.43895686, 0.43986812,\n",
       "          0.43906167, 0.42274982, 0.40161264, 0.43634015, 0.44437823,\n",
       "          0.4438726 , 0.45040503],\n",
       "         [0.4384003 , 0.4354101 , 0.4385936 , 0.43984175, 0.44153553,\n",
       "          0.43781373, 0.40392026, 0.4159014 , 0.4297735 , 0.4326549 ,\n",
       "          0.43092716, 0.44436863],\n",
       "         [0.44181007, 0.4381663 , 0.4406692 , 0.44256508, 0.44393685,\n",
       "          0.42475995, 0.3946631 , 0.42627493, 0.4431206 , 0.45439348,\n",
       "          0.45409933, 0.46224594],\n",
       "         [0.44329005, 0.43951884, 0.44241828, 0.444152  , 0.4430768 ,\n",
       "          0.41206005, 0.41668186, 0.43314895, 0.45674744, 0.4649428 ,\n",
       "          0.4644465 , 0.4699495 ],\n",
       "         [0.44433254, 0.43895376, 0.44165018, 0.443328  , 0.44123295,\n",
       "          0.41006476, 0.42405507, 0.43926486, 0.46193004, 0.46485218,\n",
       "          0.46189982, 0.46747547],\n",
       "         [0.44394317, 0.43857977, 0.44003272, 0.44083178, 0.43746543,\n",
       "          0.41506425, 0.4196755 , 0.43653303, 0.4540601 , 0.4618982 ,\n",
       "          0.45901394, 0.46599877],\n",
       "         [0.44328752, 0.43733424, 0.43800592, 0.4380853 , 0.43584302,\n",
       "          0.42455176, 0.40109622, 0.42619362, 0.43771517, 0.43985248,\n",
       "          0.44362143, 0.4655405 ],\n",
       "         [0.44203073, 0.43541613, 0.43521369, 0.4356359 , 0.43470094,\n",
       "          0.41856647, 0.3941876 , 0.41564232, 0.4426753 , 0.4415358 ,\n",
       "          0.4380893 , 0.45185727],\n",
       "         [0.44017264, 0.43318105, 0.43344873, 0.43456775, 0.4332437 ,\n",
       "          0.41354442, 0.39051047, 0.39361027, 0.42023313, 0.40031186,\n",
       "          0.40452304, 0.44763643],\n",
       "         [0.4380148 , 0.4313114 , 0.43259907, 0.43469214, 0.43293574,\n",
       "          0.4229716 , 0.39231578, 0.41172877, 0.39481005, 0.37625012,\n",
       "          0.3768392 , 0.43522435],\n",
       "         [0.4320244 , 0.4258506 , 0.42853007, 0.4314033 , 0.43076387,\n",
       "          0.41358492, 0.38819748, 0.4272147 , 0.39351976, 0.37658957,\n",
       "          0.38944378, 0.44685802],\n",
       "         [0.42012134, 0.41834772, 0.42236698, 0.42517623, 0.42667994,\n",
       "          0.40910724, 0.42633334, 0.4453333 , 0.42819485, 0.38944998,\n",
       "          0.37693876, 0.4374815 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 12, 12), dtype=float32, numpy=\n",
       " array([[[0.26000237, 0.270481  , 0.25484055, 0.24539661, 0.2416973 ,\n",
       "          0.24497104, 0.31149518, 0.39875025, 0.25602895, 0.22341171,\n",
       "          0.22545987, 0.19903442],\n",
       "         [0.24765694, 0.25981104, 0.2468717 , 0.24180438, 0.23493254,\n",
       "          0.25003982, 0.38915688, 0.33962154, 0.2827754 , 0.2710274 ,\n",
       "          0.27806944, 0.2234505 ],\n",
       "         [0.23381923, 0.24860723, 0.23844662, 0.23075819, 0.2251995 ,\n",
       "          0.30326337, 0.42775282, 0.2970657 , 0.22850673, 0.1829345 ,\n",
       "          0.18412107, 0.1513044 ],\n",
       "         [0.22781992, 0.2431151 , 0.23135342, 0.22432822, 0.22868422,\n",
       "          0.3554557 , 0.33640975, 0.2690149 , 0.17344376, 0.14045906,\n",
       "          0.14245428, 0.12034687],\n",
       "         [0.22359686, 0.24540916, 0.23446763, 0.22766623, 0.23615971,\n",
       "          0.3636975 , 0.30614868, 0.24414596, 0.15257512, 0.14082354,\n",
       "          0.15269671, 0.13028201],\n",
       "         [0.22517398, 0.24692784, 0.24102911, 0.23778707, 0.25145483,\n",
       "          0.34306866, 0.32410568, 0.2552447 , 0.18427914, 0.1527032 ,\n",
       "          0.16431297, 0.13621503],\n",
       "         [0.22783029, 0.25198802, 0.24925885, 0.24893641, 0.2580502 ,\n",
       "          0.3041152 , 0.40089956, 0.29739818, 0.25044003, 0.24176085,\n",
       "          0.22647719, 0.1380567 ],\n",
       "         [0.23292454, 0.25978673, 0.26061028, 0.25889277, 0.26269668,\n",
       "          0.32866096, 0.42974332, 0.3406881 , 0.23031157, 0.23493141,\n",
       "          0.24892013, 0.19316944],\n",
       "         [0.24046132, 0.2688843 , 0.2677939 , 0.2632387 , 0.26862907,\n",
       "          0.34933197, 0.445167  , 0.43216157, 0.32181638, 0.40416586,\n",
       "          0.38665402, 0.21022516],\n",
       "         [0.24922282, 0.27650267, 0.27125496, 0.26273248, 0.2698833 ,\n",
       "          0.3105865 , 0.43758833, 0.35682324, 0.42713767, 0.50549525,\n",
       "          0.502986  , 0.260567  ],\n",
       "         [0.2735964 , 0.29880106, 0.2878511 , 0.27612787, 0.2787353 ,\n",
       "          0.34916502, 0.45489538, 0.29322413, 0.43254086, 0.5040492 ,\n",
       "          0.4496508 , 0.21337382],\n",
       "         [0.3222754 , 0.32955983, 0.31306416, 0.30155975, 0.29540986,\n",
       "          0.36765715, 0.29682708, 0.2195445 , 0.28921998, 0.4496248 ,\n",
       "          0.50256205, 0.25138953]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 12, 12), dtype=float32, numpy=\n",
       " array([[[ 1.00000000e+00,  3.14437121e-01,  1.43090755e-01,\n",
       "           7.26767778e-02,  3.94394249e-02,  2.00930461e-02,\n",
       "           9.87890828e-03,  4.40867571e-03,  1.52961584e-03,\n",
       "           4.00149729e-04,  6.69313886e-05, -0.00000000e+00],\n",
       "         [ 3.18837047e-01,  5.90097129e-01,  3.26623440e-01,\n",
       "           1.95052281e-01,  1.16979502e-01,  6.82399869e-02,\n",
       "           3.69665213e-02,  1.78927872e-02,  8.04684777e-03,\n",
       "           2.70412280e-03,  6.42000348e-04,  8.89625444e-05],\n",
       "         [ 1.49880037e-01,  3.31400007e-01,  3.57633978e-01,\n",
       "           2.66386509e-01,  1.86684400e-01,  1.24793246e-01,\n",
       "           7.95426592e-02,  4.44660038e-02,  2.16264036e-02,\n",
       "           9.15003475e-03,  2.47819722e-03,  3.71574220e-04],\n",
       "         [ 7.69145936e-02,  2.02267066e-01,  2.72071868e-01,\n",
       "           2.74754971e-01,  2.29692787e-01,  1.78131402e-01,\n",
       "           1.26251638e-01,  7.99931809e-02,  4.48954441e-02,\n",
       "           2.10584532e-02,  7.57332379e-03,  1.51805475e-03],\n",
       "         [ 4.29520458e-02,  1.21780835e-01,  1.95338726e-01,\n",
       "           2.35963896e-01,  2.36464188e-01,  2.13673443e-01,\n",
       "           1.72666445e-01,  1.25796378e-01,  7.96578974e-02,\n",
       "           4.25913744e-02,  1.76909342e-02,  4.31646826e-03],\n",
       "         [ 2.34116279e-02,  7.32123554e-02,  1.32954106e-01,\n",
       "           1.85621515e-01,  2.18661800e-01,  2.25928411e-01,\n",
       "           2.08996505e-01,  1.71011806e-01,  1.23243459e-01,\n",
       "           7.47954771e-02,  3.45211513e-02,  9.64675006e-03],\n",
       "         [ 1.10755078e-02,  4.14547473e-02,  8.46544281e-02,\n",
       "           1.34592608e-01,  1.80146754e-01,  2.13693634e-01,\n",
       "           2.27877185e-01,  2.13272899e-01,  1.72798619e-01,\n",
       "           1.20464087e-01,  6.37236759e-02,  1.87175833e-02],\n",
       "         [ 4.68078256e-03,  2.08336841e-02,  4.99687456e-02,\n",
       "           8.89677331e-02,  1.33688003e-01,  1.84140623e-01,\n",
       "           2.23079696e-01,  2.41758808e-01,  2.27161333e-01,\n",
       "           1.80834964e-01,  1.08828500e-01,  3.70843671e-02],\n",
       "         [ 1.60644448e-03,  8.40936415e-03,  2.49608662e-02,\n",
       "           5.16790040e-02,  8.84708315e-02,  1.36429206e-01,\n",
       "           1.89400151e-01,  2.46053547e-01,  2.78216153e-01,\n",
       "           2.64991730e-01,  1.86922625e-01,  6.71814904e-02],\n",
       "         [ 4.86272969e-04,  2.63385382e-03,  9.67033394e-03,\n",
       "           2.39821915e-02,  4.85725924e-02,  8.51706117e-02,\n",
       "           1.35378256e-01,  2.01434866e-01,  2.82301813e-01,\n",
       "           3.66199732e-01,  3.21339428e-01,  1.33663043e-01],\n",
       "         [ 7.03916157e-05,  7.00403354e-04,  2.79890886e-03,\n",
       "           8.48575402e-03,  2.08903160e-02,  4.10904326e-02,\n",
       "           7.43390322e-02,  1.24343254e-01,  2.10216329e-01,\n",
       "           3.43579173e-01,  5.96714556e-01,  3.04284424e-01],\n",
       "         [ 1.36509843e-05,  9.48198867e-05,  6.37667777e-04,\n",
       "           1.77603762e-03,  4.71468968e-03,  1.16594220e-02,\n",
       "           2.25461498e-02,  4.25848588e-02,  7.76374638e-02,\n",
       "           1.52707264e-01,  3.25296551e-01,  1.00000000e+00]]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 12])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(train_inputs[1:2], train_labels[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dijkstra(tf.math.exp(x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object_0 = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "loss_object_1 = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom accuracy function\n",
    "class SameSolutionAccuracy(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='same_solution_accuracy', **kwargs):\n",
    "        super(SameSolutionAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.same_solutions = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.counter = self.add_weight(name='counter', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, cost_matrix):\n",
    "        y_true = tf.cast(y_true, tf.bool)\n",
    "        # apply the combinatorial solver (dijkstra) // parallel not possible in eager mode (python function!)\n",
    "        y_pred = tf.cast(tf.map_fn(dijkstra, y_pred), tf.bool)\n",
    "        \n",
    "        # compute the cost of the shortest path\n",
    "        \n",
    "        # invert vector (used if representation of true paths is 0-based)\n",
    "        #y_true = tf.cast(tf.math.logical_not(y_true), tf.float32)\n",
    "        #y_pred = tf.cast(tf.math.logical_not(y_pred), tf.float32)\n",
    "        \n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        #print(y_true)\n",
    "        #print(y_pred)\n",
    "        \n",
    "        y_true = tf.reshape(y_true, [-1, 144])\n",
    "        y_pred = tf.reshape(y_pred, [-1, 144])\n",
    "        cost_matrix = tf.cast(cost_matrix, tf.float32)\n",
    "        cost_matrix = tf.reshape(cost_matrix, [-1, 144])\n",
    "        \n",
    "        #print(y_true.shape)\n",
    "        \n",
    "        y_true_cost = tf.math.reduce_sum(cost_matrix * y_true, 1)\n",
    "        y_pred_cost = tf.math.reduce_sum(cost_matrix * y_pred, 1)\n",
    "        \n",
    "        print(y_true_cost)\n",
    "        print(y_pred_cost)\n",
    "        \n",
    "        # True if the cost is the same\n",
    "        equal_values = tf.cast(tf.math.less_equal(y_pred_cost, y_true_cost), tf.float32)\n",
    "        print(equal_values)\n",
    "        sum_correct_in_batch = tf.math.reduce_sum(equal_values)\n",
    "        print(sum_correct_in_batch)\n",
    "        print(y_true.shape[0])\n",
    "\n",
    "        self.same_solutions.assign_add(sum_correct_in_batch)\n",
    "        self.counter.assign_add(y_true.shape[0])\n",
    "        \n",
    "        \n",
    "        print(\"---\")\n",
    "\n",
    "    def result(self):\n",
    "        return self.same_solutions/self.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "train_samesol = SameSolutionAccuracy()\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')\n",
    "test_samesol = SameSolutionAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model_inference(images, training=True)\n",
    "        loss = loss_object_0(labels, predictions[2])\n",
    "    gradients = tape.gradient(loss, model_inference.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model_inference.trainable_variables))\n",
    "\n",
    "    train_loss(loss_object_0(labels, predictions[2]))\n",
    "    train_accuracy(labels,  predictions[0])\n",
    "    #train_samesol(labels,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def test_step(images, labels, cost_matrix):\n",
    "    predictions = model_inference(images, training=False)\n",
    "    t_loss = loss_object_0(labels, predictions[0])\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, -predictions[0])\n",
    "    #print(labels)\n",
    "    test_samesol(labels, predictions[1], cost_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, SameSol: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result() * 100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result() * 100,\n",
    "                        test_samesol.result()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([16.798828], shape=(1,), dtype=float32)\n",
      "tf.Tensor([28.805664], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([47.103516], shape=(1,), dtype=float32)\n",
      "tf.Tensor([50.506836], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([33.89746], shape=(1,), dtype=float32)\n",
      "tf.Tensor([42.396484], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([12.798828], shape=(1,), dtype=float32)\n",
      "tf.Tensor([13.199219], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([78.02246], shape=(1,), dtype=float32)\n",
      "tf.Tensor([78.42285], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([26.998047], shape=(1,), dtype=float32)\n",
      "tf.Tensor([41.00293], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([17.700195], shape=(1,), dtype=float32)\n",
      "tf.Tensor([18.5], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([55.396484], shape=(1,), dtype=float32)\n",
      "tf.Tensor([57.7959], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([18.098633], shape=(1,), dtype=float32)\n",
      "tf.Tensor([20.601562], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([48.413086], shape=(1,), dtype=float32)\n",
      "tf.Tensor([48.413086], shape=(1,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([39.208008], shape=(1,), dtype=float32)\n",
      "tf.Tensor([39.609375], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([11.999023], shape=(1,), dtype=float32)\n",
      "tf.Tensor([11.998047], shape=(1,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([11.598633], shape=(1,), dtype=float32)\n",
      "tf.Tensor([11.598633], shape=(1,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([15.199219], shape=(1,), dtype=float32)\n",
      "tf.Tensor([15.199219], shape=(1,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([62.695312], shape=(1,), dtype=float32)\n",
      "tf.Tensor([69.194336], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([20.000977], shape=(1,), dtype=float32)\n",
      "tf.Tensor([30.807617], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([31.703125], shape=(1,), dtype=float32)\n",
      "tf.Tensor([31.703125], shape=(1,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([20.098633], shape=(1,), dtype=float32)\n",
      "tf.Tensor([23.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([15.6015625], shape=(1,), dtype=float32)\n",
      "tf.Tensor([16.001953], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([22.200195], shape=(1,), dtype=float32)\n",
      "tf.Tensor([28.300781], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([28.700195], shape=(1,), dtype=float32)\n",
      "tf.Tensor([30.801758], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n",
      "tf.Tensor([45.612305], shape=(1,), dtype=float32)\n",
      "tf.Tensor([47.21289], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "test_samesol.reset_states()\n",
    "\n",
    "for test_images, test_labels, cost_matrix in test_ds:\n",
    "    test_step(test_images, test_labels, cost_matrix)\n",
    "    \n",
    "template = 'Epoch {}, Test Loss: {}, Test Accuracy: {}, SameSol: {}'\n",
    "print(template.format(epoch + 1,\n",
    "                   test_loss.result(),\n",
    "                   test_accuracy.result() * 100,\n",
    "                   test_samesol.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(val_inputs[0:2])\n",
    "x[1]\n",
    "#1-dijkstra(x[1]).shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}