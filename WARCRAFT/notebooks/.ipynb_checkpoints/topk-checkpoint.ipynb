{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils\n",
    "from typing import Any\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "# from functools import partial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for top-k distribution\n",
    "rng = np.random.RandomState(0)\n",
    "n = 10\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788\n",
      "  0.95008842 -0.15135721 -0.10321885  0.4105985 ]\n"
     ]
    }
   ],
   "source": [
    "# generate random parameters for the distribution\n",
    "theta = rng.randn(n)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible states: 252\n",
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# create all possible_states:\n",
    "combs = list(itertools.combinations(range(n), k))\n",
    "n_states = len(combs)\n",
    "assert n_states == np.math.factorial(n)/(np.math.factorial(k)*np.math.factorial(n-k))\n",
    "print('Number of possible states:', n_states)\n",
    "mat_x = np.zeros((len(combs), n))\n",
    "for i in range(n_states):\n",
    "    mat_x[i, combs[i]] = 1.\n",
    "\n",
    "print(mat_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# put all of this in pytorch\n",
    "theta_t = t.from_numpy(theta).float().requires_grad_(True)\n",
    "states_t = t.from_numpy(mat_x).float()\n",
    "\n",
    "def tow_t(_theta):\n",
    "    return states_t @ _theta\n",
    "\n",
    "def Z_t(_theta):\n",
    "    return t.log(t.sum(t.exp(tow_t(_theta))))\n",
    "\n",
    "def pmf_t(_theta):\n",
    "    return t.exp(tow_t(_theta) - Z_t(_theta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(t.sum(pmf_t(theta)))  # so far so good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check that prob(theta) is differentiable\n",
    "# attributing random value to each state\n",
    "b_t = t.abs(t.from_numpy(rng.randn(n)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1440, 1.4543, 0.7610, 0.1217, 0.4439, 0.3337, 1.4941, 0.2052, 0.3131,\n",
      "        0.8541])\n"
     ]
    }
   ],
   "source": [
    "print(b_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1251508\n"
     ]
    }
   ],
   "source": [
    "sorted_bt = np.sort(b_t.detach().numpy())\n",
    "min_value_of_exp = np.sum((sorted_bt[:5])**2) + np.sum((sorted_bt[5:] - 1)**2)\n",
    "print(min_value_of_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5104)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(index):\n",
    "    return t.sum((states_t[index] - b_t)**2)\n",
    "\n",
    "objective(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# writing explicitly the expectation of this objective summing over\n",
    "# all possible states:\n",
    "def expectation_t(_theta):\n",
    "    _pmf = pmf_t(_theta)\n",
    "    _p_values = t.stack([_pmf[i] * objective(i) for i in range(n_states)])\n",
    "    return t.sum(_p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2394, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_t(theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2238, -0.4104, -0.0290,  0.1656,  0.0979,  0.0875, -0.4432,  0.2152,\n",
       "          0.1734, -0.0808]),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that the gradient is all right\n",
    "t.autograd.grad(expectation_t(theta_t), theta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially we are now solving explicitly\n",
    "$\\min_{\\theta} \\mathbb{E}_{z\\sim p(z, \\theta)} b^\\intercal z$\n",
    "where $p(z, \\theta)$ is top-k distribution.\n",
    "\n",
    "With full optimization we simply write $\\mathbb{E}_{z\\sim p(z, \\theta)} b^\\intercal z= \\sum_{i=1}^{N} p(z_i, \\theta) b^\\intercal z_i $\n",
    "summing over all possible states, where $N=\\binom{n}{k}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def optim_loop(min_objective, lr, momentum_factor, n_steps, reinitialize=True):\n",
    "    global theta_t\n",
    "    if reinitialize:\n",
    "        theta_t = t.from_numpy(theta).float().requires_grad_(True)\n",
    "    # let's try to optimize this expectation w.r.t. theta\n",
    "    _opt = t.optim.SGD([theta_t], lr, momentum=momentum_factor)\n",
    "    _hist, _hist_expectation = [], []\n",
    "    for _t in range(n_steps):\n",
    "        _opt.zero_grad()\n",
    "        _obj = min_objective(theta_t)\n",
    "        _hist.append(_obj.detach().numpy())\n",
    "        _hist_expectation.append(expectation_t(theta_t).detach().numpy())\n",
    "        _obj.backward()\n",
    "        _opt.step()\n",
    "    return _hist, _hist_expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_optim_hist, _ = optim_loop(expectation_t, 1., 0.9, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of map state tensor(0.9986, grad_fn=<SelectBackward>)\n",
      "tensor(1.2656) 1.1251508\n"
     ]
    }
   ],
   "source": [
    "\n",
    "map_state_after_opt = np.argmax(pmf_t(theta_t).detach().numpy())\n",
    "print('probability of map state', pmf_t(theta_t)[map_state_after_opt])\n",
    "print(t.sum(states_t[map_state_after_opt] - b_t)**2, min_value_of_exp)  # should be the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([0.1440, 1.4543, 0.7610, 0.1217, 0.4439, 0.3337, 1.4941, 0.2052, 0.3131,\n",
      "        0.8541])\n"
     ]
    }
   ],
   "source": [
    "print(states_t[map_state_after_opt])\n",
    "print(b_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdcd09dae20>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(full_optim_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 204, 71, 59, 41, 127, 60, 89, 0, 96]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all good\n",
    "# now need to do STE (i.e. sampling and ignoring constraints,\n",
    "# guess treat the z's as Bernoullis') and I-MLE\n",
    "\n",
    "# reinitialize theta with the same initial value\n",
    "theta_t = t.from_numpy(theta).float().requires_grad_(True)\n",
    "\n",
    "def sample_state_from_pdf(_theta):\n",
    "    _pmft = pmf_t(_theta)\n",
    "    # print(_pmft)\n",
    "    # print(t.sum(_pmft))\n",
    "    indx_ch = rng.choice(list(range(n_states)), p=_pmft.detach().numpy())\n",
    "    return indx_ch\n",
    "\n",
    "# just check\n",
    "print([sample_state_from_pdf(theta_t) for _ in range(10)])\n",
    "\n",
    "states_t[sample_state_from_pdf(theta_t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Straight through estimator\n",
    "\n",
    "def ste_grad(grad_out):\n",
    "    return grad_out\n",
    "\n",
    "def sample(_theta):\n",
    "    _sampled_index = sample_state_from_pdf(_theta)\n",
    "    return states_t[_sampled_index]\n",
    "\n",
    "# define top-k sample dist with STE gradient\n",
    "\n",
    "class TopKTrueSamplingSTEGrad(t.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, _theta):\n",
    "        return sample(_theta)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        return ste_grad(grad_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(strategy, lr, momentum=0.9,\n",
    "               steps=50, n_rep=50, do_plot=True):\n",
    "\n",
    "    # redefine objective with given strategy\n",
    "    def obj_st(_theta):\n",
    "        return t.sum((strategy(_theta) - b_t)**2)\n",
    "\n",
    "    hist = []\n",
    "    for _ in range(n_rep):\n",
    "        stoc_obj, true_obj = optim_loop(obj_st, lr, momentum, steps)\n",
    "        hist.append(true_obj)\n",
    "\n",
    "    if do_plot:\n",
    "        mean = np.mean(hist, axis=0)\n",
    "        plt.plot(full_optim_hist)\n",
    "        plt.plot(mean)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ste_lcs = experiment(TopKTrueSamplingSTEGrad.apply, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# let's try I-MLE with faithful samples\n",
    "\n",
    "def imle_forward(ctx, _theta, _lambda, sample_strategy):\n",
    "    ctx._lambda = _lambda\n",
    "    ctx._theta = _theta\n",
    "    ctx._fw = sample_strategy(_theta)\n",
    "    return ctx._fw\n",
    "\n",
    "def imle_backward(ctx, grad_out, sample_strategy):\n",
    "    theta_prime = ctx._theta - ctx._lambda*grad_out\n",
    "    sample_prime = sample_strategy(theta_prime)\n",
    "    return ctx._fw - sample_prime\n",
    "\n",
    "class TopKTrueSamplingIMLEGradWithImplicitQ(t.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, _theta, _lambda):\n",
    "        return imle_forward(ctx, _theta, _lambda, sample)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        grad = imle_backward(ctx, grad_outputs, sample)\n",
    "        return grad, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imle_ts_ap = TopKTrueSamplingIMLEGradWithImplicitQ.apply\n",
    "imle_ts_strat = lambda _th: imle_ts_ap(_th, 2.5)\n",
    "\n",
    "imle_ts_lcs = experiment(imle_ts_strat, 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def do_plots(histories, names, savename=None, figsize=(3.2, 2.5)):\n",
    "    # computing also standard devs\n",
    "    plt.figure(figsize=figsize)\n",
    "    x_axis = list(range(50))\n",
    "\n",
    "    means = [np.mean(np.array(his), axis=0) for his in histories]\n",
    "\n",
    "    std_devs = [np.std(np.array(his), axis=0) for his in histories]\n",
    "\n",
    "    plt.plot(full_optim_hist, label='Exact Gradients')\n",
    "\n",
    "    for h, st, nm in zip(means, std_devs, names):\n",
    "        line = plt.plot(h, label=nm)\n",
    "        plt.fill_between(x_axis, h - st, h + st, alpha=0.5,\n",
    "                         color=line[0].get_color())\n",
    "\n",
    "    plt.legend(loc=0)\n",
    "    plt.ylim((0.9, 3.5))\n",
    "    plt.xlim((0, 49))\n",
    "    plt.xlabel('Optimization Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    if savename:\n",
    "        plt.savefig(savename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "do_plots([ste_lcs, imle_ts_lcs], ['STE TS', 'I-MLE RS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now let's try with MAP estimators\n",
    "\n",
    "def map(_theta):\n",
    "    arg_sort = t.argsort(_theta)[k:]\n",
    "    _x = t.zeros(_theta.size())\n",
    "    _x[arg_sort] = 1.\n",
    "    return _x\n",
    "\n",
    "print(theta_t)\n",
    "map(theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define top-k sample dist with STE gradient\n",
    "\n",
    "class TopKMAPSTEGrad(TopKTrueSamplingSTEGrad):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, _theta):\n",
    "        return map(_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ste_map_lcs = experiment(TopKMAPSTEGrad.apply, 0.03, n_rep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MAP I-MLE\n",
    "\n",
    "class TopKMAPIMLEGrad(t.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, _theta, _lambda):\n",
    "        return imle_forward(ctx, _theta, _lambda, map)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        grad = imle_backward(ctx, grad_outputs, map)\n",
    "        return grad, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imle_map = lambda _th: TopKMAPIMLEGrad.apply(_th, 2.5)\n",
    "imle_map_lcs = experiment(imle_map, 0.7, n_rep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "do_plots([ste_map_lcs, imle_map_lcs], ['STE MAP', 'I-MLE MAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# let's try perturb and map\n",
    "\n",
    "_k_gamma = 5.0\n",
    "_tau_gamma = 1.0\n",
    "\n",
    "def sog_th1(s=10):\n",
    "    return (_tau_gamma/_k_gamma)*( np.sum([rng.gamma(1.0/_k_gamma, _k_gamma/(i+1.0)) for i in range(s)] ) - np.log(s) )\n",
    "\n",
    "def perturb_and_map(ctx, _theta):\n",
    "    if hasattr(ctx, 'eps'):\n",
    "        eps = ctx.eps\n",
    "    else:\n",
    "        eps = t.tensor([sog_th1() for _ in range(n)])\n",
    "        try: ctx.eps = eps\n",
    "        except AttributeError: print('Problems with ctx')\n",
    "    theta_prime = _theta + eps\n",
    "    return map(theta_prime)\n",
    "\n",
    "perturb_and_map('', theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class TopKPerturbAndMAPIMLEGrad(t.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, _theta, _lambda):\n",
    "        return imle_forward(ctx, _theta, _lambda,\n",
    "                            lambda _th: perturb_and_map(ctx, _th))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        grad = imle_backward(ctx, grad_outputs,\n",
    "                             lambda _th: perturb_and_map(ctx, _th))\n",
    "        return grad, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imle_pam = lambda _th: TopKPerturbAndMAPIMLEGrad.apply(_th, 1.)\n",
    "imle_pam_lcs = experiment(imle_pam, .5, n_rep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "do_plots([ste_map_lcs, imle_map_lcs, imle_pam_lcs], ['STE MAP', 'I-MLE MAP', 'I-MLE PAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "do_plots([ste_lcs, ste_map_lcs, imle_ts_lcs, imle_map_lcs, imle_pam_lcs],\n",
    "         ['STE FS', 'STE MAP', 'I-MLE FS', 'I-MLE MAP', 'I-MLE PAM'],\n",
    "         figsize=(5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "do_plots([ste_lcs, ste_map_lcs, imle_ts_lcs, imle_map_lcs, imle_pam_lcs],\n",
    "         ['STE FS', 'STE MAP', 'I-MLE FS', 'I-MLE MAP', 'I-MLE PAM'],\n",
    "         figsize=(5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wrapping up with STE PAM\n",
    "\n",
    "class TopKPerturbAndMapSTEGrad(TopKTrueSamplingSTEGrad):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, _theta):\n",
    "        return perturb_and_map(ctx, _theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ste_pam_lcs = experiment(TopKPerturbAndMapSTEGrad.apply, 0.07, n_rep=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "do_plots([ste_pam_lcs, imle_pam_lcs],\n",
    "         ['STE PaM', 'I-MLE PaM'],\n",
    "         figsize=(4, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# let's try perturb and map\n",
    "\n",
    "\n",
    "def perturb_and_map_gumb(ctx, _theta):\n",
    "    if hasattr(ctx, 'eps'):\n",
    "        eps = ctx.eps\n",
    "    else:\n",
    "        eps = t.from_numpy(rng.gumbel(0.0, 1.0, n)).float()\n",
    "        try: ctx.eps = eps\n",
    "        except AttributeError: print('Problems with ctx')\n",
    "    theta_prime = _theta + eps\n",
    "    return map(theta_prime)\n",
    "\n",
    "perturb_and_map_gumb('', theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class TopKPerturbAndMAPGumbIMLEGrad(t.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, _theta, _lambda):\n",
    "        return imle_forward(ctx, _theta, _lambda,\n",
    "                            lambda _th: perturb_and_map_gumb(ctx, _th))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        grad = imle_backward(ctx, grad_outputs,\n",
    "                             lambda _th: perturb_and_map_gumb(ctx, _th))\n",
    "        return grad, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "imle_pam_g = lambda _th: TopKPerturbAndMAPGumbIMLEGrad.apply(_th, 1.)\n",
    "imle_pam_g_lcs = experiment(imle_pam_g, .5, n_rep=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "color_palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "do_plots([imle_pam_g_lcs, imle_pam_lcs, ste_pam_lcs],\n",
    "         [r'I-MLE P&M Gumb.', r'I-MLE P&M SoG', r'STE P&M SoG'],\n",
    "         figsize=(3.5, 2.7), savename='ToyTopK.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
